# ğŸ§  AI Script Reviewer CLI

Ce projet permet dâ€™analyser et de recevoir des retours intelligents sur des scripts Python via une interface en ligne de commande (CLI) alimentÃ©e par des modÃ¨les de langage (LLMs).

---

## âš™ï¸ PrÃ©requis & Installation

### 1. Cloner le projet

```bash
git clone <url-de-ton-repo>
cd <nom-du-dossier>
```

### 2. CrÃ©er et activer un environnement virtuel (optionnel mais recommandÃ©)

```bash
python -m venv .venv
source .venv/bin/activate  # Linux/macOS
.venv\Scripts\activate     # Windows
```

### 3. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

### 4. Variables dâ€™environnement (si tu utilises OpenAI)

CrÃ©e un fichier `.env` Ã  la racine du projet avec ta clÃ© :

```
OPENAI_API_KEY=your_openai_api_key_here
```

### 5. Pour utiliser Ollama

Assure-toi dâ€™avoir installÃ© [Ollama](https://ollama.com) puis :

```bash
ollama serve  # Lancer le serveur Ollama (obligatoire)
```

---

## ğŸš€ Utilisation

### Commande de base

```bash
python cli.py --file <chemin_vers_script.py> --mode <mode> --provider <provider>
```

### ğŸ”§ Arguments disponibles

- `--file` : Chemin vers un fichier `.py` Ã  analyser  
  Exemples :

  - `examples/clean_script.py`
  - `examples/buggy_script.py`

- `--mode` : Mode dâ€™analyse :

  - `test_focus` â€“ vÃ©rifie la logique et les tests
  - `mentor` â€“ feedback pÃ©dagogique
  - `strict` â€“ analyse rigoureuse, niveau expert

- `--provider` : ModÃ¨le utilisÃ© :
  - `openai` â€“ via API OpenAI (âš ï¸ quotas sur comptes gratuits)
  - `ollama` â€“ modÃ¨le local avec Ollama (âš ï¸ `ollama serve` requis)

---

## ğŸ›‘ Limitations

- `OpenAI` a un **quota limitÃ©** avec un compte gratuit.
- `Anthropic` (Claude) **non utilisÃ©** ici car uniquement accessible avec un compte **payant**.
- `Ollama` nÃ©cessite que :
  - Le serveur soit lancÃ© : `ollama serve`
  - Un modÃ¨le soit dÃ©marrÃ© : `ollama run llama3`

---

## ğŸ§ª Exemples

```bash
# Analyse avec OpenAI
python cli.py --file examples/clean_script.py --mode mentor --provider openai

# Analyse stricte avec Ollama
python cli.py --file examples/buggy_script.py --mode strict --provider ollama

# VÃ©rification logique dâ€™un script
python cli.py --file examples/clean_script.py --mode test_focus --provider openai
```

---

## âœ… Exemple de requirements.txt

Si tu nâ€™as pas encore le fichier, crÃ©e un `requirements.txt` avec :

```
python-dotenv
openai
ollama
```

Ajoute dâ€™autres libs si ton projet en dÃ©pend.

---

## ğŸ“ Organisation

```
.
â”œâ”€â”€ cli.py
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ clean_script.py
â”‚   â””â”€â”€ buggy_script.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

ğŸ‰ VoilÃ  ! Tout est prÃªt pour que tu puisses analyser tes scripts Python avec des LLMs en local ou via OpenAI.
